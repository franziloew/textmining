---
title: "Regression"
subtitle: ""
author: "Franziska Löw"
date: ""
output: 
  html_document:
    toc: true
    toc_float: true
    theme: "lumen"
    highlight: "tango"
    code_folding: show
    self_contained: true
---

```{r include=FALSE}
library(ggplot2)     # Static data visualization
library(dplyr)       # Data manipulation
library(stringr)     # String manipulation
library(lubridate)   # Date and time manipulation
library(purrr)       # Functional programming
library(tidyr)       # Reshaping
library(magrittr)    # Advanced piping
library(pushoverr)   # Pushover notifications
library(readr)       # Importing data
library(data.table)
library(stm)
library(readxl)
library(Matrix)

library(igraph)
library(corrplot)
library(ggpmisc)
library(ggiraph)
library(RColorBrewer) 
library(ggrepel)
library(scales)      # Scales
library(viridis)     # Viridis color scales

library(tidytext)    # Tidy text mining
library(stringdist)  # String distances
library(proxy)       # Distance measures

# Theming
quartzFonts(
  Roboto =
    c("Roboto-Light",
      "Roboto-Bold",
      "Roboto-Regular",
      "Roboto-Thin")
)

theme_set(
  theme_bw(base_family = "Roboto", base_size = 8) +
    theme(
      plot.title = element_text(size = 10,
                                margin = margin(0, 0, 4, 0, "pt")),
      plot.subtitle = element_text(size = 12),
      plot.caption = element_text(size = 6),
      plot.background   = element_rect("#fafafa", "#fafafa"),
      panel.background  = element_rect("#fafafa"),
      panel.border = element_blank()
    )
)

rm(list=ls())
col <- brewer.pal(6,"Dark2")
source("func/functions.R")
```

# 1. The online news market

## Pageviews
```{r}
views1 <- read.csv("../data/alexa/Historical_Traffic_Trends__Pageviews_Percent_1.csv", comment.char="#")
views2 <- read.csv("../data/alexa/Historical_Traffic_Trends__Pageviews_Percent_2.csv", comment.char="#")

views <- left_join(views1, views2 %>% 
                     select(-Metric), by = "Date") %>%
  mutate(date = as.Date(Date, "%m/%d/%Y")) %>%
  select(- c(Metric,Date)) %>%
  gather(key="site", value="views", focus.de:tagesspiegel.de)
```

```{r}
# keeps <- c("spiegel.de", "focus.de", "zeit.de","bild.de",
#           "tagesschau.de")
#drop <- c("stern.de","sueddeutsche.de")

# reach <- reach %>%
#   mutate(date = as.Date(Date, "%m/%d/%Y")) %>%
#   select(- c(Metric,Date)) %>%
#   gather(key="site", value="reach", focus.de:n.tv.de) %>%
#  filter(!site %in% drop) 

views <- views %>%
  mutate(site = ifelse(site=="bild.de","Bild.de",site),
       site = ifelse(site=="focus.de","FOCUS ONLINE",site),
       site = ifelse(site=="spiegel.de","SPIEGEL ONLINE",site),
       site = ifelse(site=="zeit.de","ZEIT ONLINE",site),
       site = ifelse(site=="tagesschau.de","Tagesschau.de",site),
       site = ifelse(site=="zdf.de","ZDF.de",site),
       site = ifelse(site=="welt.de","DIE WELT",site),
       site = ifelse(site=="n-tv.de","n-tv.de",site))

```

```{r}
p1 <- views %>%
  filter(date > as.POSIXct("2017-05-31")) %>%
  ggplot(aes(date, views, color=site)) +
  geom_line(show.legend = F) +
  geom_text_repel(data = views[views$date==max(views$date), ],
                  aes(date, views, label=site),
                  size=2.8, show.legend = F, seed = 1) +
  scale_x_date(limits = c(as.Date("2017-05-31"),as.Date("2018-02-15")),
               breaks = date_breaks("1 month"), 
               labels=date_format("%B %y", tz="CET")) +
  theme(
      #legend.position   = "none",
      legend.text       =  element_text(size=6),
      axis.text.y       = element_text(size = 8)
    ) +
  labs(x="", y="pageviews", color="", title = "", 
      caption = "Source: Alexa Internet, Inc. (www.alexa.com)" )

p1

ggsave(plot= p1,
filename = "../figs/reach.png", device = "png",
width = 6, height = 4,
        dpi = 600
)
```

```{r}
# calculate percentual change
views$perc_change <- (views$views - lag(views$views, n=1)) / (views$views*100)

p1 <- views %>% 
  filter(date >= as.Date("2017-09-17") &
                   date <= as.Date("2017-10-01")) %>%
  ggplot(aes(date, perc_change, color=factor(site))) +
  geom_line(show.legend = F) +
  geom_text_repel(data = views[views$date=="2017-09-24", ],
                  aes(date, perc_change, label=site),
                  size=3, show.legend = F, seed = 5) +
  #scale_color_manual(values = brewer.pal(8,"Dark2")) +
  scale_x_date(breaks = date_breaks("1 day"), labels=date_format("%d.%m.", tz="CET")) +
  labs(x="",y="% change", color="") +
  theme(
      legend.text       =  element_text(size=6),
      axis.text.y       = element_text(size = 8)
    ) 

p1

ggsave(plot= p1,
filename = "../figs/perc_change.png", device = "png",
width = 6, height = 4,
        dpi = 600
)
```

## Traffic source

```{r}
source1 <- read.csv("../data/alexa/Traffic_Sources_1.csv", 
                    comment.char="#", stringsAsFactors = F)
source2 <- read.csv("../data/alexa/Traffic_Sources_2.csv", 
                    comment.char="#", stringsAsFactors = F)

source <- left_join(source1, source2,
                    by=c("Date","Metric")) %>%
  select(- c(Date)) %>%
  gather(key="site", value="traffic", 
         focus.de:tagesspiegel.de)


source <- source %>%
  mutate(site = ifelse(site=="bild.de","Bild.de",site),
       site = ifelse(site=="focus.de","FOCUS ONLINE",site),
       site = ifelse(site=="spiegel.de","SPIEGEL ONLINE",site),
       site = ifelse(site=="zeit.de","ZEIT ONLINE",site),
       site = ifelse(site=="tagesschau.de","Tagesschau.de",site),
       site = ifelse(site=="zdf.de","ZDF.de",site),
       site = ifelse(site=="welt.de","DIE WELT",site),
       site = ifelse(site=="n-tv.de","n-tv.de",site))

```

```{r}
p1 <- ggplot(source, aes(site, traffic, fill=Metric,
                   label = round(traffic, digits = 2))) +
  geom_col(alpha = 0.8) +
  geom_text(size = 2, position = position_stack(vjust = 0.5)) +
  labs(x = "", y = "Percentage of total traffic", 
       caption = "Source: Alexa Internet, Inc. (www.alexa.com)") +
  theme(axis.text.x = element_text(angle = 45, size = 8 ))

p1

ggsave(plot= p1,
filename = "../figs/traffic_source.png", device = "png",
width = 6, height = 4,
        dpi = 600
)
```


## Keywords
```{r message=FALSE, warning=FALSE}
setwd("../data/alexa/keywords/")
filenames <- list.files(pattern = ".tsv$")

# create an empty list that will serve as a container to receive the incoming files
list.data<-list()
 
# create a loop to read in your data
for (i in 1:length(filenames)) {
  list.data[[i]]<-read.delim(filenames[i], comment.char="#")
}

# Create DF
keywords.df <- as.data.frame(list.data[1])

for (i in 2:length(filenames)) {
  keywords.df <- rbind(keywords.df, as.data.frame(list.data[i]))
}
```

```{r}
keepsite <- c("tagesschau.de", "spiegel.de", "zeit.de", 
              "bild.de", "welt.de", "focus.de")

keywords.df.reduced <- keywords.df %>% 
  filter(nchar(as.character(site))>1) %>% filter(site %in% keepsite)
```

```{r}
keywords.df <- keywords.df %>%
  mutate(site = as.character(site)) %>%
  mutate(site = ifelse(site=="bild.de","Bild.de",site),
       site = ifelse(site=="focus.de","FOCUS ONLINE",site),
       site = ifelse(site=="spiegel.de","SPIEGEL ONLINE",site),
       site = ifelse(site=="zeit.de","ZEIT ONLINE",site),
       site = ifelse(site=="tagesschau.de","Tagesschau.de",site),
       site = ifelse(site=="deutschlandfunk.de","DLF",site),
       site = ifelse(site=="zdf.de","ZDF.de",site),
       site = ifelse(site=="welt.de","DIE WELT",site),
       site = ifelse(site=="n-tv.de","n-tv.de",site))
```

### Search Traffic %
```{r}
p1 <- keywords.df %>%
  arrange(desc(Percent_of_traffic)) %>%
  group_by(site) %>%
  top_n(10, Percent_of_traffic) %>%
  ungroup() %>%
  ggplot(aes(reorder(term, Percent_of_traffic), 
             Percent_of_traffic, fill=site)) +
  geom_col(fill=col[1], show.legend = FALSE) +
  theme_bw(base_family = "Roboto", base_size = 7) +
  coord_flip() +
  facet_wrap(~site, scales = "free") +
  labs(x= "", y = "Search traffic %", 
       title = "",
       caption = "Source: Alexa Internet, Inc. (www.alexa.com)")

p1

ggsave(plot= p1,
filename = "../figs/search_traffic.png", device = "png",
width = 9, height = 5,
        dpi = 600
)
```

### Share of voice
```{r}
keyword1 <- c("nachrichten", "news", "bundestagswahl 2017",
            "groko", "jamaika")

keyword2 <- c("cdu","csu","spd","fdp","afd",
           "die linke","die grünen")

```

```{r}
p1 <- keywords.df %>%
  filter(term %in% keyword1) %>%
  ggplot(aes(site,
             Share_of_voice, fill=term)) +
  geom_col(fill=col[3], show.legend = F) +
  coord_flip() +
  facet_grid(~term, scales = "free") +
  labs(x= "", y = "Share of voice",
       title = ""
       )

p1

ggsave(plot= p1,
filename = "../figs/keywords1.png", device = "png",
width = 6, height = 4,
        dpi = 600
)
```

```{r}
p1 <- keywords.df %>%
  filter(term %in% keyword2) %>%
  ggplot(aes(site,
             Share_of_voice, fill=term)) +
  geom_col(fill=col[3], show.legend = F) +
  coord_flip() +
  facet_grid(~term) +
  labs(x= "", y = "Share of voice",
       caption = "
  Source: Alexa Internet, Inc. (www.alexa.com)
      ",
       title = ""
       )

p1

ggsave(plot= p1,
filename = "../figs/keywords2.png", device = "png",
width = 6, height = 4,
        dpi = 600
)
```

# 2. Data 
```{r caching, echo = FALSE}
load("../output/btw_combined.Rda")
```

## Distribution of articles
```{r message=FALSE, warning=FALSE}
ggsave({
  btw %>%
  ggplot(aes(site)) +
  geom_bar(fill=col[1], alpha= .8) +
  labs(x="", y="Number of articles") +
  theme(
      legend.position   = "none"
    )
  
},
filename = "../figs/bar.png", device = "png", 
width = 6, height = 4,
        dpi = 600)
```

```{r message=FALSE, warning=FALSE}
ggsave({
  btw %>%
  group_by(date) %>%
  dplyr::summarise(obs = n()) %>%
  ggplot(aes(date, obs)) +
  geom_line(color=col[3]) +
  geom_vline(aes(xintercept=as.Date("2017-09-24")),
             linetype = 2, color=col[2]) +
  scale_color_manual(values = col) +
  labs(x="", y="number of articles",color="") +
  scale_x_date(breaks = date_breaks("1 month"), labels=date_format("%B", tz="CET")) +
  theme(
      legend.position   = "none",
      axis.title.x      = element_blank(),
      axis.text       = element_text(size = 8)
    )
},
filename = "../figs/timeline.png", device = "png",width = 7, height = 4,
dpi = 600
)

```

# 3. Model Results
```{r caching, echo = FALSE}
load("../output/models/STM_stemmed2 40 .Rda")
```

## Label topics
```{r}
sagelabs <- sageLabels(stmOut, 25)
```

```{r}
stmOut$settings$covariates$yvarlevels
```

### Label topics based on Bild.de

After reviewing a sample of articles assigned to the respective topic, we assign a shorter name to the topics based on the most common words in order to improve readability and traceability.
```{r}
sagelabs$cov.betas[[5]]$problabels[,1:10]
```

```{r}
topics <- matrix(c(1, "Great coalition", 2, "Merkel vs. CSU", 3, "Jamaica coalition", 
                   4, "Diesel scandal", 5, "Merkel as chancellor", 6, "Seehover vs. Söder", 
                   7, "political trends after the election", 8, "Merkel vs.Schulz", 9, "AfD election results", 
                   10, "Steinmeier,Federal President", 11, "IT themes (Data policy, Wifi, Telekom)", 
                   12, "Federal Election in social media", 13, "Climate policy", 14, "G20 Hamburg", 
                   15, "error (text processing failure)", 16, "Education, Pension policy",
                   17, "Reports on individuals", 18, "Family reunion refugees", 19, "Polls federal election", 
                   20, "AfD top candidates Weidel, Storch", 21, "M.Schwesig (SPD)",
                   22, "elections in Niedersachsen", 23, "Court sentences (NSU, Böhmermann vs. Erdogan)", 
                   24, "election capaigns & political talkshows", 25, "German armed forces", 26, "W.Schäuble", 
                   27, "C.Lindner FDP", 28, "Turkey, Russia", 29, "railway problems (DBahn)", 
                   30, "H.Kohl obituary", 31, "AfD Gauland, Höcke", 32, "Asylum claims and deportation", 
                   33, "EU policies", 34, "DIE LINKE", 35, "SPD", 36, "Islam and antisemitism in GER", 
                   37, "AfD in parliament", 38, "Terror attacks (GER)  & police reports", 
                   39, "Church", 40, "RAF"), ncol=2, byrow=T)

topics.df <- as.data.frame(topics) %>%
  transmute(topic_name = paste(V1, V2, sep=": "),
         topic = 1:40) 
```

## Assign a topic to each document (choose by gamma)
```{r Extract wtp and dtp}
# Document-topic probabilities
stmOut %>% tidy("theta") -> theta

top_topics <- theta %>% 
  group_by(document) %>%
  mutate(therank = rank(-gamma, ties.method = "random")) %>%
  filter(therank == 1) %>%
  select(- therank)

btw.2 <- btw %>%
  mutate(document = articleID) %>%
  inner_join(.,top_topics, by="document") %>%
  ## Combine with Topic label
  left_join(., topics.df, by="topic") %>%
  mutate(allocation = 1) 
```

### now we can inspect the unclear topics
```{r}
btw %>% filter(topic==17) %>% select(title, gamma, url) %>%
  htmlTable::htmlTable(align="l")
```

## Expected topic proportions

### in the overall corpus
```{r}
frequency <- as.data.frame(colMeans(stmOut$theta)) %>% 
  mutate(frequency = colMeans(stmOut$theta),
    topic=paste(topics[,1],topics[,2], sep=": ")) 

p1 <- ggplot(frequency, aes(x=reorder(topic, frequency), y=frequency)) + 
    geom_col(fill=col[1], alpha=0.8) +
    coord_flip() +
    labs(x="", y="expected frequency") +
    theme(axis.text.x = element_text(size=8),
          axis.text.y = element_text(size=11),
          axis.title = element_text(size=10))

p1

ggsave(plot = p1, filename = "../figs/topic_proportion.png", device = "png",width = 8, height = 12,
dpi = 600)
```

### by newspaper
```{r}
plotNewspaperHistogram <- function(topic){
  tab <- tapply(stmOut$theta[,topic], stmOut$settings$covariates$betaindex, mean)
  tab <- as.data.frame(tab) %>% 
    mutate(site=stmOut$settings$covariates$yvarlevels)
  
  ggplot(data=tab, aes(x=site, y=tab)) +
    geom_col(fill=col[3]) +
    coord_flip() +
    theme(axis.text = element_text(size=8),
          axis.title = element_text(size=10)) +
    labs(x="", y=paste("expected frequency of topic",topics.df[topic,2], sep=" ")) 
}
```

```{r}
# Topic 3
plotNewspaperHistogram(1)
```

### Difference in topic prevalence
The estimateEffect() function explores how prevalence of topics varies across documents according to document covariates (metadata). First, users must specify the variable that they wish to use for calculating an effect. If there are multiple variables specified in estimateEffect(), then all other variables are held at their sample median. These parameters include the expected proportion of a document that belongs to a topic as a function of a covariate, or a first difference type estimate, where topic prevalence for a particular topic is contrasted for two groups.

```{r}
effect <- estimateEffect(c(1:40) ~site+s(month), stmOut, 
                         metadata = out$meta, uncertainty = "None")
#plot.estimateEffect(effect, "month", topics=c(33), method = "continuous", npoints=500)
```

```{r}
summary(effect)
```

```{r}
tables <- vector(mode="list", length = length(effect$topics))

for (i in seq_along(effect$topics)) {
  sims <- lapply(effect$parameters[[i]], function(x) stm:::rmvnorm(500, x$est, x$vcov))
  sims <- do.call(rbind, sims)
  est <- colMeans(sims)
  se <- sqrt(apply(sims,2, stats::var))
  tval <- est/se
  rdf <- nrow(effect$data) - length(est)
  p <- 2*stats::pt(abs(tval), rdf, lower.tail = FALSE)
  topic <- i
  
  coefficients <- cbind(topic, est, se, tval, p)
  rownames(coefficients) <- attr(effect$parameters[[1]][[1]]$est, "names") 
  colnames(coefficients) <- c("topic", "Estimate", "Std. Error", "t value", "p")
  tables[[i]] <- coefficients
}

out <- list(call=effect$call, topics=effect$topics, tables=tables)
```

```{r}
coeff <- as.data.frame(do.call(rbind,out$tables))

coeff <- coeff %>% 
  mutate(parameter = rownames(coeff),
         parameter = gsub("site", "", parameter),
         parameter = ifelse(parameter == "s(month)1", "1_July", parameter),
         parameter = ifelse(parameter == "s(month)2", "2_August", parameter),
         parameter = ifelse(parameter == "s(month)3", "3_September", parameter),
         parameter = ifelse(parameter == "s(month)4", "4_October", parameter),
         parameter = ifelse(parameter == "s(month)5", "5_November", parameter),
         parameter = ifelse(parameter == "s(month)6", "6_December", parameter),
         signifcant = ifelse(p <= 0.5,"yes","no")) %>%
  left_join(., topics.df, by="topic")
```

```{r}
sites <- c("(Intercept)", "DIE WELT", "FOCUS ONLINE","SPIEGEL ONLINE", "Tagesschau.de","ZEIT ONLINE")

p1 <- coeff %>% filter(parameter %in% sites) %>%
  ggplot(aes(x = reorder(topic_name,topic, decreasing=F), y = Estimate, fill=factor(signifcant))) +
  geom_col() +
  scale_fill_manual(values = col[c(2,1)]) +
  coord_flip() +
  facet_wrap(~parameter, ncol = 6) +
  labs(x="", fill="significant at\nthe 5% level") +
  theme(axis.text.x = element_text(angle=90))

p1

ggsave(plot = p1, filename = "../figs/estimates_site.png", device = "png",width = 9, height = 5,
dpi = 600)
```

```{r}
p1 <- coeff %>% filter(!parameter %in% sites) %>%
  ggplot(aes(x = reorder(topic_name,topic, decreasing=F), y = Estimate, 
             fill=factor(signifcant))) +
  geom_col() +
  scale_fill_manual(values = col[c(2,1)]) +
  coord_flip() +
  facet_wrap(~parameter, ncol = 6) +
  labs(x="", fill="significant at\nthe 5% level") +
  theme(axis.text.x = element_text(angle=90))

p1

ggsave(plot = p1, filename = "../figs/estimates_month.png", device = "png",width = 9, height = 5,
dpi = 600)
```

## Topic Correlation
```{r}
## Create Dataframe with correlations

cor <- cor(stmOut$theta[stmOut$settings$covariates$betaindex==1,])
colnames(cor) <- 1:40
  
df <- as.data.frame(cor) %>% 
  mutate(topic = 1:40) %>%
  melt(., id="topic", value.name="corr") %>%
  mutate(site = stmOut$settings$covariates$yvarlevels[1])

for (i in 2:6) {
  cor <- cor(stmOut$theta[stmOut$settings$covariates$betaindex==i,])
  colnames(cor) <- 1:40
  
  df1 <- as.data.frame(cor) %>% 
    mutate(topic = 1:40) %>%
    melt(., id="topic", value.name="corr") %>%
    mutate(site = stmOut$settings$covariates$yvarlevels[i])
  
  df <- rbind(df,df1)
}
```

```{r}
df <- df %>% 
  left_join(.,topics.df, by = "topic") %>%
  mutate(topic1 = topic,
         topic_name1 = topic_name,
         topic = as.numeric(variable)) %>%
  select(-topic_name) %>%
  left_join(., topics.df, by="topic")
```

```{r}
p1 <- df %>%
  filter(corr>0.1 & corr < 1) %>%
  ggplot(aes(reorder(topic_name1,topic1), topic_name, 
             fill=corr)) +
  geom_tile() +
  facet_wrap(~site, ncol = 6) +
  scale_fill_distiller(palette = "Spectral", trans = "reverse") + 
  labs(x="", y="", fill="correlation") +
  theme_bw(base_family = "Roboto", base_size = 10) +
  theme(axis.text.x = element_text(angle=90, size = 6),
        #plot.background = element_rect(fill = 'transparent', colour = 'transparent'),
        strip.background = element_rect(fill = 'transparent', colour = 'transparent'),
        axis.ticks = element_line(colour = 'transparent'))

p1

ggsave(plot = p1, filename = "../figs/topic_correlation.png", device = "png",width = 9, height = 5,
dpi = 600)
```


### Overlapping Correlation
Pairs of topics where an edge exists in both Newspaper, we denote with a light blue dot. Pairs of topics where Newspaper1, but not Newspaper2 have an edge between them, we denote with a red square, and those where Newspaper2, but not Newspaper1 have an edge between them we denote with a blue square.
We then sort the matrix by topics that are similarly correlated with other topics in Newspaper1 and Newspaper2 to those that are not similarly correlated.
```{r}
png("../figs/overlapping_correlation.png")
topicCorrCompare(1,5)
dev.off()
```

### Distance metric

Compute the Jensen Shannon divergence of the word-topic probability. The K-by-V (number of words in the vocabulary) matrix logbeta contains the natural log of the probability of seeing each word conditional on the topic.

```{r}
stmOut$settings$covariates$yvarlevels[1]
```

```{r}
comb.matrix <- matrix(0, nrow= 36, ncol = 2)

y <- 1
for (i in 1:6) {
  for (j in 1:6) {
    comb.matrix[y,1] <- stmOut$settings$covariates$yvarlevels[i]
    comb.matrix[y,2] <- stmOut$settings$covariates$yvarlevels[j]
    y <- y+1
  }
}
```

```{r}
# Create empty matrix
kld.matrix <- matrix(0, nrow = nrow(comb.matrix), ncol = 40)
names(kld.matrix) <- 1:40
# Populate matrix with JSD Values

x <- 1

for (i in 1:6) {
  
      print(paste("ylevel = ", i))
    base <- exp(stmOut$beta$logbeta[[i]])
    compare1 <- exp(stmOut$beta$logbeta[[1]])
    compare2 <- exp(stmOut$beta$logbeta[[2]])
    compare3 <- exp(stmOut$beta$logbeta[[3]])
    compare4 <- exp(stmOut$beta$logbeta[[4]])
    compare5 <- exp(stmOut$beta$logbeta[[5]])
    compare6 <- exp(stmOut$beta$logbeta[[6]])
  
  for (j in 1:40) {
    
    print(paste("topic = ", j))
    kld.matrix[x,j] <- JSD(base[j,],compare1[j,])
    kld.matrix[x+1,j] <- JSD(base[j,],compare2[j,])
    kld.matrix[x+2,j] <- JSD(base[j,],compare3[j,])
    kld.matrix[x+3,j] <- JSD(base[j,],compare4[j,])
    kld.matrix[x+4,j] <- JSD(base[j,],compare5[j,])
    kld.matrix[x+5,j] <- JSD(base[j,],compare6[j,])

  }
    x <- x+6
}

```

```{r}
## Create DF
kld.df <- as.data.frame(kld.matrix) 
colnames(kld.df) <- 1:40

kld.df <- kld.df %>% mutate(News1 = comb.matrix[,1],
         News2 = comb.matrix[,2]) %>%
  melt(.,id=c("News1","News2"), value.name="JSD",
       variable.name = "topic") %>%
  mutate(topic = as.integer(topic)) %>%
  left_join(., topics.df, by="topic")
```

```{r}
cols <- rev(brewer.pal(11, 'RdYlBu'))


p1 <- kld.df %>%
  filter(!topic %in% c("11","15")) %>%
  filter(News1!=News2) %>%
  ggplot(aes(News2, factor(topic_name), fill = JSD)) + 
  geom_tile() + 
  facet_grid(~News1) + 
  scale_fill_gradientn(colours = cols) +
  labs(x="", y="") +
  theme_bw(base_family = "Roboto", base_size = 11) +
  theme(axis.text.x = element_text(angle=90),
        plot.background = element_rect(fill = 'transparent', colour = 'transparent'),
        strip.background = element_rect(fill = 'transparent', colour = 'transparent'),
        axis.ticks = element_line(colour = 'transparent'))

p1

ggsave(plot = p1, filename = "../figs/jsd.png", device = "png",width = 10, height = 8,
dpi = 600)
```






