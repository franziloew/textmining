---
title: "Regression"
subtitle: ""
author: "Franziska Löw"
date: ""
output: 
  html_document:
    toc: true
    toc_float: true
    theme: "lumen"
    highlight: "tango"
    code_folding: show
    self_contained: true
---

```{r include=FALSE}
library(ggplot2)     # Static data visualization
library(dplyr)       # Data manipulation
library(stringr)     # String manipulation
library(lubridate)   # Date and time manipulation
library(purrr)       # Functional programming
library(tidyr)       # Reshaping
library(magrittr)    # Advanced piping
library(pushoverr)   # Pushover notifications
library(readr)       # Importing data
library(data.table)
library(stm)
library(readxl)
library(Matrix)

library(igraph)
library(ggpmisc)
library(ggiraph)
library(RColorBrewer) 
library(ggrepel)
library(scales)      # Scales
library(viridis)     # Viridis color scales

library(tidytext)    # Tidy text mining
library(stringdist)  # String distances
library(proxy)       # Distance measures
  
library(htmlwidgets) # JS visuliaztions
library(htmltools)   # Arbitrary html

# Theming
quartzFonts(
  Roboto =
    c("Roboto-Light",
      "Roboto-Bold",
      "Roboto-Regular",
      "Roboto-Thin")
)

theme_set(
  theme_bw(base_family = "Roboto", base_size = 8) +
    theme(
      plot.title = element_text(size = 10,
                                margin = margin(0, 0, 4, 0, "pt")),
      plot.subtitle = element_text(size = 12),
      plot.caption = element_text(size = 6),
      panel.border = element_blank()
    )
)

rm(list=ls())
col <- brewer.pal(6,"Dark2")
```

# 1. The online news market

## Pageviews
```{r}
views1 <- read.csv("../data/alexa/Historical_Traffic_Trends__Pageviews_Percent_1.csv", comment.char="#")
views2 <- read.csv("../data/alexa/Historical_Traffic_Trends__Pageviews_Percent_2.csv", comment.char="#")

views <- left_join(views1, views2 %>% 
                     select(-Metric), by = "Date") %>%
  mutate(date = as.Date(Date, "%m/%d/%Y")) %>%
  select(- c(Metric,Date)) %>%
  gather(key="site", value="views", focus.de:tagesspiegel.de)
```

```{r}
# keeps <- c("spiegel.de", "focus.de", "zeit.de","bild.de",
#           "tagesschau.de")
#drop <- c("stern.de","sueddeutsche.de")

# reach <- reach %>% 
#   mutate(date = as.Date(Date, "%m/%d/%Y")) %>%
#   select(- c(Metric,Date)) %>%
#   gather(key="site", value="reach", focus.de:n.tv.de) %>%
#  filter(!site %in% drop) %>%
#   mutate(site = ifelse(site=="bild.de","Bild.de",site),
#        site = ifelse(site=="focus.de","FOCUS ONLINE",site),
#        site = ifelse(site=="spiegel.de","SPIEGEL ONLINE",site),
#        site = ifelse(site=="zeit.de","ZEIT ONLINE",site),
#        site = ifelse(site=="tagesschau.de","Tagesschau.de",site),
#        site = ifelse(site=="zdf.de","ZDF.de",site),
#        site = ifelse(site=="welt.de","DIE WELT",site),
#        site = ifelse(site=="n-tv.de","n-tv.de",site))

```

```{r}
p1 <- views %>%
  filter(date > as.POSIXct("2017-05-31")) %>%
  ggplot(aes(date, views, color=site)) +
  geom_line(show.legend = F) +
  geom_text_repel(data = views[views$date==max(views$date), ],
                  aes(date, views, label=site),
                  size=2.8, show.legend = F, seed = 5) +
  scale_x_date(limits = c(as.Date("2017-05-31"),as.Date("2018-02-15")),
               breaks = date_breaks("1 month"), 
               labels=date_format("%B %y", tz="CET")) +
  theme(
      #legend.position   = "none",
      legend.text       =  element_text(size=6),
      plot.background   = element_rect("#fafafa", "#fafafa"),
      panel.background  = element_rect("#fafafa"),
      axis.title.x      = element_blank(),
      axis.text.y       = element_text(size = 8)
    ) +
  labs(x="", y="pageviews", color="", title = "", 
      caption = "Source: Alexa Internet, Inc. (www.alexa.com)" )

p1

ggsave(plot= p1,
filename = "../figs/reach.png", device = "png",
width = 6, height = 4,
        dpi = 600
)
```

```{r}
# calculate percentual change
views$perc_change <- (views$views - lag(views$views, n=1)) / (views$views*100)

p1 <- views %>% 
  filter(date >= as.Date("2017-09-17") &
                   date <= as.Date("2017-10-01")) %>%
  ggplot(aes(date, perc_change, color=factor(site))) +
  geom_line(show.legend = F) +
  geom_text_repel(data = views[views$date=="2017-09-24", ],
                  aes(date, perc_change, label=site),
                  size=2.8, show.legend = F, seed = 5) +
  #scale_color_manual(values = brewer.pal(8,"Dark2")) +
  scale_x_date(breaks = date_breaks("1 day"), labels=date_format("%d.%m.", tz="CET")) +
  labs(x="",y="% change", color="") +
  theme(
      legend.text       =  element_text(size=6),
      plot.background   = element_rect("#fafafa", "#fafafa"),
      panel.background  = element_rect("#fafafa"),
      axis.title.x      = element_blank(),
      axis.text.y       = element_text(size = 8)
    ) 

p1

ggsave(plot= p1,
filename = "../figs/perc_change.png", device = "png",
width = 6, height = 4,
        dpi = 600
)
```

## Traffic source

```{r}
source1 <- read.csv("../data/alexa/Traffic_Sources_1.csv", 
                    comment.char="#", stringsAsFactors = F)
source2 <- read.csv("../data/alexa/Traffic_Sources_2.csv", 
                    comment.char="#", stringsAsFactors = F)

source <- left_join(source1, source2,
                    by=c("Date","Metric")) %>%
  select(- c(Date)) %>%
  gather(key="site", value="traffic", 
         focus.de:tagesspiegel.de)
```

```{r}
p1 <- ggplot(source, aes(site, traffic, fill=Metric,
                   label = round(traffic, digits = 2))) +
  geom_col(alpha = 0.8) +
  geom_text(size = 2, position = position_stack(vjust = 0.5)) +
  labs(x = "", y = "Percentage of total traffic", 
       caption = "Source: Alexa Internet, Inc. (www.alexa.com)") +
  theme(axis.text.x = element_text(angle = 45, size = 7 ))

p1

ggsave(plot= p1,
filename = "../figs/traffic_source.png", device = "png",
width = 6, height = 4,
        dpi = 600
)
```


## Keywords
```{r message=FALSE, warning=FALSE}
setwd("../data/alexa/keywords/")
filenames <- list.files(pattern = ".tsv$")

# create an empty list that will serve as a container to receive the incoming files
list.data<-list()
 
# create a loop to read in your data
for (i in 1:length(filenames)) {
  list.data[[i]]<-read.delim(filenames[i], comment.char="#")
}

# Create DF
keywords.df <- as.data.frame(list.data[1])

for (i in 2:length(filenames)) {
  keywords.df <- rbind(keywords.df, as.data.frame(list.data[i]))
}
```

```{r}
keepsite <- c("tagesschau.de", "spiegel.de", "zeit.de", "deutschlandfunk.de",
              "zdf.de", "bild.de", "welt.de", "stern.de", "sueddeutsche.de", "focus.de")

keywords.df <- keywords.df %>% 
  filter(nchar(as.character(site))>1)
#  filter(site %in% keepsite)

unique(keywords.df$site)
```

### Search Traffic %
```{r}
p1 <- keywords.df %>%
  arrange(desc(Percent_of_traffic)) %>%
  group_by(site) %>%
  top_n(10, Percent_of_traffic) %>%
  ungroup() %>%
  ggplot(aes(reorder(term, Percent_of_traffic), 
             Percent_of_traffic, fill=site)) +
  geom_col(show.legend = FALSE) +
  theme_bw(base_family = "Roboto", base_size = 4) +
  coord_flip() +
  facet_wrap(~site, scales = "free") +
  labs(x= "", y = "Search traffic %", 
       title = "",
       caption = "Source: Alexa Internet, Inc. (www.alexa.com)")

p1

ggsave(plot= p1,
filename = "../figs/search_traffic.png", device = "png",
width = 7, height = 4,
        dpi = 600
)
```

### Share of voice
```{r}
keyword1 <- c("nachrichten", "news", "bundestagswahl 2017",
            "groko", "jamaika")

keyword2 <- c("cdu","csu","spd","fdp","afd",
           "die linke","die grünen")

```

```{r}
p1 <- keywords.df %>%
  filter(term %in% keyword1) %>%
  ggplot(aes(site,
             Share_of_voice, fill=term)) +
  geom_col(show.legend = F) +
  coord_flip() +
  facet_grid(~term, scales = "free") +
  labs(x= "", y = "Share of voice",
       title = ""
       )

p1

ggsave(plot= p1,
filename = "../figs/keywords1.png", device = "png",
width = 6, height = 4,
        dpi = 600
)
```

```{r}
p1 <- keywords.df %>%
  filter(term %in% keyword2) %>%
  ggplot(aes(site,
             Share_of_voice, fill=term)) +
  geom_col(show.legend = F) +
  coord_flip() +
  facet_grid(~term) +
  labs(x= "", y = "Share of voice",
       caption = "
  Source: Alexa Internet, Inc. (www.alexa.com)
      ",
       title = ""
       )

p1

ggsave(plot= p1,
filename = "../figs/keywords2.png", device = "png",
width = 6, height = 4,
        dpi = 600
)
```

## Audience Network
```{r}
focus <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_focus.csv", header=FALSE, comment.char="#")
spiegel <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_spiegel.csv", header=FALSE, comment.char="#")
bild <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_bildde.csv", header=FALSE, comment.char="#")
zeit <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_zeitde.csv", header=FALSE, comment.char="#")
tagesschau <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_tagesschau.csv", header=FALSE, comment.char="#")

zdf <-  read.csv("../data/audience_network/Audience_Overlap_1_15_2018_zdf.csv.crdownload.csv", header=FALSE, comment.char="#")
#stern <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_stern.csv", header=FALSE, comment.char="#")
welt <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018 _welt.csv", header=FALSE, comment.char="#")
```

```{r}
focus <- focus[-1,1:2] 
colnames(focus) <- c("site","focus.de")

spiegel <- spiegel[-1,1:2] 
colnames(spiegel) <- c("site","spiegel.de")

bild <- bild[-1,1:2] 
colnames(bild) <- c("site","bild.de")

zeit <- zeit[-1,1:2] 
colnames(zeit) <- c("site","zeit.de")

tagesschau <- tagesschau[-1,1:2] 
colnames(tagesschau) <- c("site","tagesschau.de")

zdf <- zdf[-1,1:2] 
colnames(zdf) <- c("site","zdf.de")

welt <- welt[-1,1:2] 
colnames(welt) <- c("site","welt.de")
```

```{r}
# combine dataframes
network_df <- left_join(focus[1:80,], spiegel[1:80,], by="site") %>%
  left_join(., bild[1:80,], by = "site") %>%
  left_join(., zeit[1:80,], by = "site") %>%
  left_join(., tagesschau[1:80,], by = "site") %>%
  left_join(., zdf[1:80,], by = "site") %>%
  left_join(., welt[1:80,], by = "site")

network_df <- na.omit(network_df)

melted <- network_df %>%
    gather(key="seed", value="score", focus.de:welt.de) %>%
  mutate(score = as.integer(score),
         site = as.factor(site),
         seed = as.factor(seed))
```

```{r}
p1 <- ggplot(melted, aes(seed, site, fill=score)) +
  geom_tile() +
  scale_fill_gradient(low="gray95",high=col[3]) +
  scale_x_discrete(labels=c("bilde.de" = "Bild.de", 
                            "focus.de" = "FOCUS ONLINE", 
                            "spiegel.de" = "SPIEGEL ONLINE",
                            "tagesschau.de" = "Tagesschau.de", 
                            "welt.de" ="DIE WELT",
                            "zdf.de" = "ZDF.de",
                            "zeit.de" = "ZEIT ONLINE")) +
  labs(x="", y="",  caption = "
  Source: Alexa Internet, Inc. (www.alexa.com)
      ") +
  theme(
      legend.text       =  element_text(size=6),
      plot.background   = element_rect("#fafafa", "#fafafa"),
      panel.background  = element_rect("#fafafa"),
      axis.title.x      = element_blank(),
      axis.text.x = element_text(size=8, angle = 45),
      axis.text.y       = element_text(size = 8)
    ) 

ggsave(plot= p1,
filename = "../figs/audience.png", device = "png",
width = 5, height = 6,
        dpi = 600
)

p1
```

# 2. Data 
```{r caching, echo = FALSE}
load("../output/btw_combined.Rda")
```

## Distribution of articles
```{r message=FALSE, warning=FALSE}
ggsave({
  btw %>%
  ggplot(aes(site)) +
  geom_bar(fill=col, alpha= .8) +
  labs(x="", y="Number of articles") +
  theme(
      legend.position   = "none",
      plot.background   = element_rect("#fafafa", "#fafafa"),
      plot.title        = element_text(size = 18),
      plot.subtitle     = element_text(size = 8),
      plot.caption      = element_text(size = 7),
      panel.background  = element_rect("#fafafa"),
      axis.title.x      = element_blank(),
      axis.text.y       = element_text(size = 8)
    )
  
},
filename = "../figs/bar.png", device = "png", 
width = 6, height = 4,
        dpi = 600)
```

```{r message=FALSE, warning=FALSE}
ggsave({
  btw %>%
  group_by(date, site) %>%
  dplyr::summarise(obs = n()) %>%
  ggplot(aes(date, obs, color = site)) +
  geom_line() +
  #geom_vline(aes(xintercept=as.Date("2017-09-24")),
  #           linetype = 2, color="grey40") +
  #geom_vline(aes(xintercept=as.Date("2017-11-20")),
  #               linetype = 2, color="grey40") +
  scale_color_manual(values = col) +
  labs(x="", y="Count",color="") +
  scale_x_date(breaks = date_breaks("1 month"), labels=date_format("%B", tz="CET")) +
  theme(
      #legend.position   = "none",
      plot.background   = element_rect("#fafafa", "#fafafa"),
      plot.title        = element_text(size = 18),
      plot.subtitle     = element_text(size = 8),
      plot.caption      = element_text(size = 7),
      #panel.grid        = element_blank(),
      panel.background  = element_rect("#fafafa"),
      axis.title.x      = element_blank(),
      axis.text.y       = element_text(size = 8)
    )
},
filename = "../figs/timeline.png", device = "png",width = 7, height = 4,
dpi = 600
)

```

# 3. Model Results
```{r caching, echo = FALSE}
load("../output/models/STM_stemmed2 40 .Rda")
```

## Label topics
```{r}
sagelabs <- sageLabels(stmOut, 100)
```

```{r}
stmOut$settings$covariates$yvarlevels
```

### Label topics based on Bild.de

After reviewing a sample of articles assigned to the respective topic, we assign a shorter name to the topics based on the most common words in order to improve readability and traceability.
```{r}
sagelabs$cov.betas[[1]]$problabels[,1:10]
```

```{r}
topics <- matrix(c(1, "Great coalition", 2, "Merkel,election campaign", 3, "Jamaica coalition", 
                   4, "Diesel scandal", 5, "Merkel chancellor", 6, "Seehover vs. Söder", 
                   7, "Germany, EU, Jamaika", 8, "Merkel vs.Schulz", 9, "AfD election results", 
                   10, "Steinmeier,Federal President", 11, "unclear (Schröder, Google)", 
                   12, "Federal Election in social media", 13, "Climate policy", 14, "G20 Hamburg", 
                   15, "error", 16, "Education, Pension policy", 17, "Reports on individuals",
                   18, "Family reunion refugees", 19, "Polls federal election", 
                   20, "AfD top candidates Weidel, Storch", 21, "M.Schwesig (SPD)",
                   22, "elections in Niedersachsen", 23, "Böhmermann vs. Erdogan", 
                   24, "political talkshows", 25, "German armed forces", 26, "W.Schäuble", 
                   27, "C.Lindner FDP", 28, "Turkey, Russia", 29, "A.Merkel Youtube", 
                   30, "H.Kohl obituary", 31, "AfD Gauland, Höcke", 32, "Asylum claims and deportation", 
                   33, "EU policies", 34, "DIE LINKE", 35, "SPD", 36, "Islam and antisemitism in GER", 
                   37, "AfD in parliament", 38, "Terror attacks (GER)  & police reports", 
                   39, "Church", 40, "RAF"), ncol=2, byrow=T)
```

## Assign a topic to each document (choose by gamma)
```{r Extract wtp and dtp}
# Document-topic probabilities
stmOut %>% tidy("theta") -> theta

top_topics <- theta %>% 
  group_by(document) %>%
  mutate(therank = rank(-gamma, ties.method = "random")) %>%
  filter(therank == 1) %>%
  select(- therank)

topics.df <- as.data.frame(topics) %>% transmute(topic = as.integer(V1),
                                 topic_name = paste(topic, V2, sep=": "))

btw.2 <- btw %>%
  mutate(document = articleID) %>%
  inner_join(.,top_topics, by="document") %>%
  ## Combine with Topic label
  left_join(., topics.df, by="topic") %>%
  mutate(allocation = 1) 
```

### now we can inspect the unclear topics
```{r}
btw %>% filter(topic==17) %>% select(title, gamma, url) %>%
  htmlTable::htmlTable(align="l")
```

## Expected topic proportions

### in the overall corpus
```{r}
frequency <- as.data.frame(colMeans(stmOut$theta)) %>% 
  mutate(frequency = colMeans(stmOut$theta),
    topic=paste(topics[,1],topics[,2], sep=": ")) 

p1 <- ggplot(frequency, aes(x=reorder(topic, frequency), y=frequency)) + 
    geom_col(fill=col[1], alpha=0.8) +
    coord_flip() +
    labs(x="", y="expected frequency") +
    theme(axis.text = element_text(size=8),
          axis.title = element_text(size=10))

p1

#ggsave(plot = p1, filename = "../figs/topic_proportion.png", device = "png",width = 8, height = 12,
#dpi = 600)
```

## by newspaper
```{r}
plotNewspaperHistogram <- function(topic){
  tab <- tapply(stmOut$theta[,topic], stmOut$settings$covariates$betaindex, mean)
  tab <- as.data.frame(tab) %>% 
    mutate(site=stmOut$settings$covariates$yvarlevels)
  
  ggplot(data=tab, aes(x=site, y=tab)) +
    geom_col(fill=col[3]) +
    coord_flip() +
    theme(axis.text = element_text(size=8),
          axis.title = element_text(size=10)) +
    labs(x="", y=paste("expected frequency of topic",topics.df[topic,2], sep=" ")) 
}
```

```{r}
# Topic 3
plotNewspaperHistogram(1)
```

## Topic Correlation
```{r}
topicCorrelation <- function(ylevel) {
  cormat <- cor(stmOut$theta[stmOut$settings$covariates$betaindex==ylevel,])
  adjmat <- ifelse(cormat > .04,1,0)
  
  corr <- list()
  corr$posadj <- adjmat
  corr$poscor <- cormat*adjmat
  corr$cor <- ifelse(abs(cormat)>.04,cormat,0)
  
  x <- corr$posadj[1:nrow(corr$posadj),1:nrow(corr$posadj)]

  g<- graph.adjacency(x, mode="undirected", weighted=TRUE, diag=FALSE)

  E(g)$size <- 1
  E(g)$lty <- 2
  E(g)$color <- "black"
  V(g)$label <- topics[,2]
  layout <- layout_nicely

  plot.igraph(g, layout=layout_nicely, vertex.color="white", label.font = "Roboto",
     vertex.frame.color="grey", vertex.size=1, vertex.label.cex=.6, edge.color="red",
     edge.width=1, main=paste("Topic correlation", stmOut$settings$covariates$yvarlevels[ylevel]))
}
```

```{r}
topicCorrelation(5)
```

### Overlapping Correlation
```{r}
topicCorrCompare <- function(ylevel1, ylevel2) {
  
  # find all edges between topics where they exhibit a positive correlation above 0.1
  cormat <- cor(stmOut$theta[stmOut$settings$covariates$betaindex==ylevel1,])
  adjmat <- ifelse(cormat > .1,1,0)
  
  corr.1 <- list()
  corr.1$posadj <- adjmat
  corr.1$poscor <- cormat*adjmat
  corr.1$cor <- ifelse(abs(cormat)>.04,cormat,0)
  
  # Ylevel 2
  cormat <- cor(stmOut$theta[stmOut$settings$covariates$betaindex==ylevel2,])
  adjmat <- ifelse(cormat > .1,1,0)
  
  corr.2 <- list()
  corr.2$posadj <- adjmat
  corr.2$poscor <- cormat*adjmat
  corr.2$cor <- ifelse(abs(cormat)>.04,cormat,0)
  
  # Prepare plot
  g.1 <- graph.adjacency(corr.1$cor, mode="undirected", weighted = T, diag = F) 
  g.2 <- graph.adjacency(corr.2$cor, mode = "undirected", weighted = T, diag = F)
  
  inter.graph <- graph.intersection(g.1, g.2)
  added.subgraph <- graph.difference(g.1, inter.graph)
  subs.subgraph <- graph.difference(g.2, inter.graph)
  
  # Styling
  E(added.subgraph)$color <- col[1]
  E(subs.subgraph)$color <- col[2]
  E(inter.graph)$color <- col[3]
  
  # Matrix
  g.whole<-graph.union(inter.graph,added.subgraph,subs.subgraph)
  V(g.whole)$color<-col[3]
  E(g.whole)$color <- col[2]
  E(g.whole)[1:length(E(inter.graph))]$color<-col[3]
  E(g.whole)[(length(E(inter.graph))+1):(length(E(inter.graph))+length(E(added.subgraph)))]$color<-col[1]

  inter.list <- get.edgelist(inter.graph)
  list.1 <- get.edgelist(added.subgraph)
  list.2 <- get.edgelist(subs.subgraph)
  
  # Set Frame
  cormat <- matrix(0, nrow=100, ncol=100)
  for(i in 1:nrow(inter.list)){
    cormat[inter.list[i,1], inter.list[i,2]] <- .5
    cormat[inter.list[i,2], inter.list[i,1]] <- .5
    }
  
  for(i in 1:nrow(list.1)){
    cormat[list.1[i,1], list.1[i,2]] <- -1
    cormat[list.1[i,2], list.1[i,1]] <- -1
    }

  for(i in 1:nrow(list.2)){
    cormat[list.2[i,1], list.2[i,2]] <- 1
    cormat[list.2[i,2], list.2[i,1]] <- 1
    }

  cormat <- cormat[as.numeric(topics[,1]),as.numeric(topics[,1])]
  topics2 <- sapply(topics[,2], function (x) str_replace(x, "\n", ""))
  rownames(cormat) <- colnames(cormat) <- topics.df$topic_name
  
  only.1 <- apply(cormat,1, function (x) sum(x==1))
  only.2 <- apply(cormat,1, function (x) sum(x==-1))
  both <- apply(cormat,1, function (x) sum(x==.5))
  all <- apply(cormat,1, function (x) sum(x!=0))
  disagree <- only.1/all + only.2/all
  
  
  disagreed <- order(disagree, decreasing=F)
  list <- topics[disagreed,2]
  disagreemat <- cormat[disagreed, disagreed]
  rownames(disagreemat) <- topics2[disagreed]
  colnames(disagreemat) <- topics2[disagreed]

  corrplot(disagreemat, cl.pos="n", tl.col="black", tl.cex=.5)
  legend(40,20, c(paste(stmOut$settings$covariates$yvarlevels[ylevel1]), paste(stmOut$settings$covariates$yvarlevels[ylevel2]), "Both", "None"),
         col=c("darkred", "darkblue", "lightblue", "white"), 
         pch=c(15,15,16,16), cex = 0.7, box.lty = 0)
}
```

Pairs of topics where an edge exists in both Newspaper, we denote with a light blue dot. Pairs of topics where Newspaper1, but not Newspaper2 have an edge between them, we denote with a red square, and those where Newspaper2, but not Newspaper1 have an edge between them we denote with a blue square.
We then sort the matrix by topics that are similarly correlated with other topics in Newspaper1 and Newspaper2 to those that are not similarly correlated.
```{r}
topicCorrCompare(3,5)
```

## How they talk about GroKo differently




