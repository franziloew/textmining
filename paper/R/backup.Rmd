---
title: "Topic Modeling of News"
author: "Franziska LÃ¶w"
date: "`r format(Sys.Date())`"
output: github_document
---

```{r, include=FALSE}
# load the packages
libs <- c("tidytext","tidyr","readr","lubridate","tm","stm","RColorBrewer",
          "plyr","dplyr","class","knitr","kableExtra","cldr","data.table",
          "htmlTable","ggplot2","gridExtra","jsonlite","stringr","scales","rjson")
lapply(libs, library, character.only = TRUE)
```

## Load Data
```{r, include=FALSE}
#Load Data
rm(list = ls())
```

## Audience Network
```{r}
focus <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_focus.csv", header=FALSE, comment.char="#")
spiegel <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_spiegel.csv", header=FALSE, comment.char="#")
bild <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_bildde.csv", header=FALSE, comment.char="#")
zeit <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_zeitde.csv", header=FALSE, comment.char="#")
tagesschau <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_tagesschau.csv", header=FALSE, comment.char="#")

zdf <-  read.csv("../data/audience_network/Audience_Overlap_1_15_2018_zdf.csv.crdownload.csv", header=FALSE, comment.char="#")
#stern <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018_stern.csv", header=FALSE, comment.char="#")
welt <- read.csv("../data/audience_network/Audience_Overlap_1_15_2018 _welt.csv", header=FALSE, comment.char="#")
```

```{r}
focus <- focus[-1,1:2] 
colnames(focus) <- c("site","focus.de")

spiegel <- spiegel[-1,1:2] 
colnames(spiegel) <- c("site","spiegel.de")

bild <- bild[-1,1:2] 
colnames(bild) <- c("site","bild.de")

zeit <- zeit[-1,1:2] 
colnames(zeit) <- c("site","zeit.de")

tagesschau <- tagesschau[-1,1:2] 
colnames(tagesschau) <- c("site","tagesschau.de")

zdf <- zdf[-1,1:2] 
colnames(zdf) <- c("site","zdf.de")

welt <- welt[-1,1:2] 
colnames(welt) <- c("site","welt.de")
```

```{r}
# combine dataframes
network_df <- left_join(focus[1:80,], spiegel[1:80,], by="site") %>%
  left_join(., bild[1:80,], by = "site") %>%
  left_join(., zeit[1:80,], by = "site") %>%
  left_join(., tagesschau[1:80,], by = "site") %>%
  left_join(., zdf[1:80,], by = "site") %>%
  left_join(., welt[1:80,], by = "site")

network_df <- na.omit(network_df)

melted <- network_df %>%
    gather(key="seed", value="score", focus.de:welt.de) %>%
  mutate(score = as.integer(score),
         site = as.factor(site),
         seed = as.factor(seed))
```

```{r}
p1 <- ggplot(melted, aes(seed, site, fill=score)) +
  geom_tile() +
  scale_fill_gradient(low="gray95",high=col[3]) +
  scale_x_discrete(labels=c("bilde.de" = "Bild.de", 
                            "focus.de" = "FOCUS ONLINE", 
                            "spiegel.de" = "SPIEGEL ONLINE",
                            "tagesschau.de" = "Tagesschau.de", 
                            "welt.de" ="DIE WELT",
                            "zdf.de" = "ZDF.de",
                            "zeit.de" = "ZEIT ONLINE")) +
  labs(x="", y="",  caption = "
  Source: Alexa Internet, Inc. (www.alexa.com)
      ") +
  theme(
      legend.text       =  element_text(size=6),
      plot.background   = element_rect("#fafafa", "#fafafa"),
      panel.background  = element_rect("#fafafa"),
      axis.title.x      = element_blank(),
      axis.text.x = element_text(size=8, angle = 45),
      axis.text.y       = element_text(size = 8)
    ) 

ggsave(plot= p1,
filename = "../figs/audience.png", device = "png",
width = 5, height = 6,
        dpi = 600
)

p1
```

## Summary Stats
```{r}
df %>%
  group_by(site) %>%
  summarise(obs = n(),
    fb_shares.mean = mean(fb_shares),
            fb_shares.max = max(fb_shares),
            text_length.mean = mean(text_lenght),
            text_length.max = max(text_lenght)) %>%
  htmlTable(align = "l")
```

## Sample Articles

```{r Document classification}
set.seed(9272)
posts_classification.sdt <-
  posts.dtp %>% 
  #filter(topic %in% keeps) %>%
  group_by(articleID = document) %>% 
  summarise(topic = min(topic[gamma == max(gamma)]), gamma = max(gamma)) %>% 
  ungroup() %>%
  inner_join(btw %>% 
               #filter(topic %in% keeps) %>%
               select(title, title_text, articleID, topic_name, site),
              by = "articleID") %>%
  mutate(topic_title = 
           paste0("Topic ", formatC(topic, flag = "0", width = 2), 
                  " - ", topic_name)) %>%
  group_by(topic_name, site) %>% 
  top_n(10, gamma) %>%
  sample_n(3, replace = TRUE) %>%
  mutate(row = row_number()) %>% 
  ungroup() 
```

```{r}
posts_classification.sdt %>%
  select(site,topic_title,title) %>%
  htmlTable::htmlTable(align="l")
```


## Estimating the Effect of Covariates

### Difference in topic prevalence
The estimateEffect() function explores how prevalence of topics varies across documents according to document covariates (metadata). First, users must specify the variable that they wish to use for calculating an effect. If there are multiple variables specified in estimateEffect(), then all other variables are held at their sample median. These parameters include the expected proportion of a document that belongs to a topic as a function of a covariate, or a first difference type estimate, where topic prevalence for a particular topic is contrasted for two groups.

```{r}
effect <- estimateEffect(c(1:40) ~site+s(month), stmOut, 
                         metadata = out$meta, uncertainty = "None")
plot.estimateEffect(effect, "month", topics=c(33), method = "continuous", npoints=500)
```

```{r}
summary(effect)
```

Expected difference in topic probability by news source (with 95% Confidence Intervals). 
parameter "covariate": String of the name of the main covariate of interest. Must be enclosed in quotes. All other covariates within the formula specified in estimateEffect will be kept at their median.
```{r}
for (i in 1:40){
  
  png(paste0("../figs/estimate_effect",i,".png"))
  plot(prep, "site", method = "pointestimate", topics = i,
       labeltype = "custom", custom.labels = unique(prep$data$site),
       ylab = "", xlab = "Mean topic proportion in corpus",
       main = paste0("Topic ",topicLabel$topic_name[i]),
       xlim = c(-.05,0.2))
  dev.off()
}

#plot(prep, "site", method = "pointestimate", topics = keeps[1])
```

```{r}
# for (i in 1:40){
#   plot(prep, "month", method = "continuous", topics = i,
#        printlegend = F,
#        ylab = "", xlab = "Mean topic proportion in corpus",
#        main = paste0("Topic ",i,": ",topicLabel$topic_name[i]))
# }
```

```{r}
p<- posts.dtp %>%
  left_join(., btw %>% select(document, topic_name,
                              site, month),
            by="document")  %>%
  group_by(site, topic, topic_name, month) %>%
  summarize(gamma_mean = mean(gamma)) %>%
  #filter(month!=5) %>%
  ggplot(aes(x=month, y=gamma_mean, fill=factor(topic), text=topic_name)) +
  geom_col() +
  facet_wrap(~site) +
  #facet_grid(~site) +
  theme(legend.position = "none") +
  xlab("Month")

ggplotly(p)
```

What is the distribution of the gamma value?
```{r}
ggsave(plot={
  btw %>%
    #filter(topic %in% keeps) %>%
  ggplot(aes(gamma)) +
  geom_density(fill="blue",alpha=.5,color="blue") 
},
filename = "../figs/gamma_dist.png",
       width = 8, height = 6, device = "png", dpi=600)
```

## Topic Timeline
```{r Data for topic trends chart, message=FALSE, warning=FALSE}
set.seed(7292)
btw %>% 
  mutate(date = as.POSIXct(date),
         allocation = 1) %>%
  mutate(post_period = 
           date %>% with_tz("Europe/Paris") %>% 
           floor_date("week")) %>%
  # Summarise into tidy dataframe
  group_by(post_period, topic, topic_name) %>% dplyr::summarise(articles = sum(allocation)) %>%
  # Mark peaks 
  group_by(topic_name) %>% dplyr::mutate(peak = ifelse(articles==max(articles),1,0)) -> chart_topic_trends.dt
```

```{r message=FALSE, warning=FALSE}
ggsave(
  plot = {
    ggplot(chart_topic_trends.dt, 
       aes(post_period, articles, color=topic_name)) +
  geom_line(show.legend = FALSE) +
  scale_color_manual(
            values = rainbow(60) %>% 
              adjustcolor(red.f = 0.6, green.f = 0.6, blue.f = 0.6)
          ) +
      geom_text_repel(data= subset(chart_topic_trends.dt,peak==1 & articles >=25),
            aes(post_period,articles,label=topic_name), vjust = -1, size = 2,
            size=2.8) +
      geom_vline(aes(xintercept=as.POSIXct("2017-09-23")),
                 linetype = 2, color="grey20") +
      geom_vline(aes(xintercept=as.POSIXct("2017-11-19")),
                 linetype = 2, color="grey20") +
  ylim(c(0,120)) +
    theme(
      legend.position = "none",
      #plot.background   = element_rect("#fafafa", "#fafafa"),
      plot.title        = element_text(size = 18),
      plot.subtitle     = element_text(size = 8),
      plot.caption      = element_text(size = 7),
      panel.grid        = element_blank(),
      #panel.background  = element_rect("#fafafa"),
      axis.title.x      = element_blank(),
      axis.text.y       = element_text(size = 8)
    )
  },
  device = "png",
  filename = "../figs/topic-timeline.png",
  dpi = 600, height = 5, width = 8
)
```


### Topic Distribution by News Page

A common accusation leveled against traditional news media is the amount of bias in reporting various topics. We try to explore the topic distribution of news articles.

```{r}
library(radarchart)
```

```{r}
btw %>% 
  group_by(site, topic, topic_name) %>%
  summarise(articles = sum(allocation)) %>%
  ungroup() %>%
  group_by(site) %>%
  mutate(perc_articles = articles/sum(articles)) %>% 
  ungroup() %>%
  transmute(site=site,
            perc_articles=perc_articles,
            topic=topic_name) %>%
  spread(key=site, value=perc_articles) %>%
  ungroup() %>%
  mutate(topic=factor(topic)) -> radar
```

```{r}
chartJSRadar(scores = radar, labelSize = 9, maxScale = 0.1, 
             showToolTipLabel = TRUE,
             width = 8, height = 8)
```


## Sentiment analysis

```{r}
sent <- c(
  # positive WÃ¶rter
  readLines("dict/SentiWS_v1.8c_Negative.txt",
            encoding = "UTF-8"),
  # negative WÃ¶rter
  readLines("dict/SentiWS_v1.8c_Positive.txt",
            encoding = "UTF-8")
) %>% lapply(function(x) {
  # Extrahieren der einzelnen Spalten
  res <- strsplit(x, "\t", fixed = TRUE)[[1]]
  return(data.frame(words = res[1], value = res[2],
                    stringsAsFactors = FALSE))
}) %>%
  bind_rows %>% 
  mutate(word = gsub("\\|.*", "", words) %>% tolower,
         value = as.numeric(value)) %>% 
  # manche WÃ¶rter kommen doppelt vor, hier nehmen wir den mittleren Wert
  group_by(word) %>% summarise(value = mean(value)) %>% ungroup
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
# Tokenize text
token <- btw %>%
  unnest_tokens(word, text_cleaned1)

# Combine with sentiment values
sentDF <- left_join(token, sent, by="word") %>% 
  mutate(sentiment = as.numeric(value)) %>% 
  filter(!is.na(sentiment)) 
```

```{r fig.height=12}
sentDF %>% group_by(topic_name, site) %>% 
  summarize(sentiment = mean(sentiment)) %>%
  ggplot(aes(topic_name, sentiment, fill=site)) +
  geom_col(fill=col[3], alpha=0.8) +
    facet_wrap(~site, ncol = 1) +
    labs(x="", y="sentiment value") +
    theme(axis.text.x = element_text(size=10, angle = 90))
```

### Radar plot
```{r}
sentDF %>% 
  select(site, topic_name, sentiment) %>%
  spread(key=site, value=sentiment) %>%
  ungroup() -> radar
```

```{r}
chartJSRadar(scores = radar, labelSize = 8, maxScale = 1000, showToolTipLabel = TRUE,
             addDots = FALSE, showLegend = FALSE,
             width = 8, height = 8)
```

### Using sentimentr
```{r}
library(sentimentr)
```

```{r}
# Load dictionaries (from: http://wortschatz.uni-leipzig.de/de/download)
neg_df <- read_tsv("dict/SentiWS_v1.8c_Negative.txt", col_names = FALSE)
pos_df <- read_tsv("dict/SentiWS_v1.8c_Positive.txt", col_names = FALSE)

sentiment_df <- bind_rows(neg_df,pos_df)
names(sentiment_df) <- c("Wort_POS", "polarity", "Inflektionen")

sentiment_df %>% 
  mutate(words = str_sub(Wort_POS, 1, regexpr("\\|", .$Wort_POS)-1),
         words = tolower(words)
         #POS = str_sub(Wort_POS, start = regexpr("\\|", .$Wort_POS)+1)
         ) %>%
  select(words, polarity) -> sentiment_df

sentiment_df <- rbind(sentiment_df, c("nicht",-0.8))

sentiment_df %>% mutate(polarity = as.numeric(polarity)) %>%
  as_key() -> sentiment_df
```

```{r}
btw.reg %>% 
  mutate(text_split = get_sentences(text)) %$%
  sentiment(text_split,
               polarity_dt = sentiment_df) -> btw_sentiment

btw_sentiment_doclevel <- btw_sentiment %>%
  group_by(element_id) %>%
  summarize(sentiment = mean(sentiment)) 

btw.reg <- left_join(btw.reg, btw_sentiment_doclevel %>%
                       mutate(document = element_id) %>%
                       select(document, sentiment),
                      by="document")
btw.reg %>%
  group_by(site) %>%
  mutate(ave_sentiment = mean(sentiment, na.rm = T)) -> plot_btw
```

```{r}
p1 <- plot_btw %>%
  ggplot(aes(sentiment, factor(site), color=topic_name, 
             text=paste(document,": ",title))) +
  geom_point(alpha=.5, shape=1) +
  xlim(c(-0.25,0.1)) +
  facet_wrap(~topic_name) +
  labs(y="") +
  theme(legend.position = "none")

ggplotly(p1)
```

```{r}
btw.reg %>% 
  filter(document==372) %>%
  mutate(text_split = get_sentences(text)) %$%
  sentiment_by(text_split,
               polarity_dt = sentiment_df) %>%
  sentimentr::highlight()
```

```{r}
btw.reg %>% 
  filter(document==4) %>% select(text_cleaned)
```

### Radar
#### with ggiraphExtra
```{r}
require(ggiraphExtra)
```

```{r}
btw.reg %>%
  group_by(site, topic_name) %>%
  summarize(sentiment = mean(sentiment, na.rm = T)) %>%
  spread(topic_name, sentiment) -> radar
  ungroup() %>%
  mutate(topic=factor(topic_name)) -> radar
```

```{r}
ggsave(plot={
  ggRadar(radar, aes(color=site), rescale = FALSE,
        legend.position = "none") 
  facet_wrap(~topic)
},
file="../figs/radar.png",
dpi=600,
height = 7,
width = 9
)
```

#### with radarchart

```{r}
btw.reg %>% 
  group_by(site, topic, topic_name) %>%
  summarise(sentiment = mean(sentiment, na.rm = TRUE)) %>%
  ungroup() %>%
  transmute(site=site,
            sentiment=sentiment,
            topic=paste(topic, topic_name, sep=": ")) %>%
  spread(key=site, value=sentiment) %>%
  ungroup() %>%
  mutate(topic = factor(topic))-> radar
```

```{r}
chartJSRadar(scores = radar, labelSize = 8, maxScale = 0.1, showToolTipLabel = TRUE,
             addDots = FALSE, showLegend = FALSE,
             width = 8, height = 8)
```


