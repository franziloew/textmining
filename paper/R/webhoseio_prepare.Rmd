---
title: "Topic Modeling of News"
author: "Franziska LÃ¶w"
date: "`r format(Sys.Date())`"
output: github_document
---

```{r, include=FALSE}
# load the packages
libs <- c("tidytext","tidyr","readr","lubridate","tm","stm","RColorBrewer",
          "plyr","dplyr","class","knitr","kableExtra","cldr","data.table",
          "htmlTable","ggplot2","gridExtra","jsonlite","stringr","scales","rjson")
lapply(libs, library, character.only = TRUE)

```

# Load and prepare Dataframe

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
rm(list = ls())

# create a character vector, with each file name represented by an entry
june <- list.files("../data/webhoseio/2017-06", pattern="*.json", full.names=TRUE) 
july <- list.files("../data/webhoseio/2017-07", pattern="*.json", full.names=TRUE) 
aug <- list.files("../data/webhoseio/2017-08", pattern="*.json", full.names=TRUE) 
sep <- list.files("../data/webhoseio/2017-09", pattern="*.json", full.names=TRUE) 


# a list in which each element is one of your original JSON files
myJSON <- lapply(c(june,july,aug,sep), function(x) fromJSON(file=x)) 
#myJSON <- lapply(june, function(x) fromJSON(file=x)) 

length(myJSON)
```

## Convert List to Dataframe

```{r, eval=FALSE, include=FALSE}
site <- NULL
title <- NULL
text <- NULL
published <- NULL
section <- NULL

fb_shares <- NULL
fb_likes <- NULL
fb_comments <- NULL
gplus_shares <- NULL
linkedin_shares <- NULL
stumbledupon_shares <- NULL

#external_links <- NULL

for (i in 1:length(myJSON)){
  site <- append(site, myJSON[[i]]["thread"][[1]]["site"][[1]])
  title <- append(title, myJSON[[i]]["title"][[1]])
  text <- append(text, myJSON[[i]]["text"][[1]])
  published <- append(published, myJSON[[i]]["published"][[1]])
  section <- append(section, myJSON[[i]]["thread"][[1]]["section_title"][[1]])
  
  fb_shares <- append(fb_shares, myJSON[[i]]["thread"][[1]]["social"][[1]]["facebook"][[1]][["shares"]])
  fb_likes <- append(fb_likes, myJSON[[i]]["thread"][[1]]["social"][[1]]["facebook"][[1]][["likes"]])
  fb_comments <- append(fb_likes, myJSON[[i]]["thread"][[1]]["social"][[1]]["facebook"][[1]][["comments"]])
  
  gplus_shares <- append(gplus_shares, myJSON[[i]]["thread"][[1]]["social"][[1]]["gplus"][[1]][["shares"]])
  linkedin_shares <- append(gplus_shares, myJSON[[i]]["thread"][[1]]["social"][[1]]["linkedin"][[1]][["shares"]])
  stumbledupon_shares <- append(stumbledupon_shares, myJSON[[i]]["thread"][[1]]["social"][[1]]["stumbledupon"][[1]]["shares"][[1]])
  
  external_links <- append(external_links, length(myJSON[[i]]["external_links"][[1]]))
  
}

df <- cbind(site, title, text, published, section, fb_shares, fb_likes, gplus_shares, external_links)
df <- data.frame(df, stringsAsFactors = FALSE)
```

```{r}
rm(site, title, text, published, fb_shares, fb_likes, section, external_links)
```

## Clean Data
```{r}
df %>%
  mutate(fb_shares = as.numeric(fb_shares),
         fb_likes = as.numeric(fb_likes),
         gplus_shares = as.numeric(gplus_shares),
         external_links = as.numeric(external_links)) -> df
```

### Date
```{r, eval=FALSE, include=FALSE}
# .... date
df$date <- substr(df$published, 1,10)
df$date <- as.POSIXct(df$date, format ="%Y-%m-%d")

#df <- subset(df, df$date > "2017-09-01")
```

## Count number of terms in a string
```{r}
df %>% filter(site != "zdf.de") -> df

df$text_lenght <- sapply(gregexpr("\\S+", df$text), length)
```

```{r, eval=FALSE, include=FALSE}
# Save file
save(df, linkedin_shares, file="../output/news_cleaned.Rda")
```

## Save by Site
```{r}
df %>% filter(site=="stern.de") %>% write.csv(.,file = "../output/stern.csv")
df %>% filter(site=="focus.de") %>% write.csv(.,file = "../output/focus.csv")
df %>% filter(site=="zeit.de") %>% write.csv(.,file = "../output/zeit.csv")
df %>% filter(site=="wdr.de") %>% write.csv(.,file = "../output/wdr.csv")
df %>% filter(site=="spiegel.de") %>% write.csv(.,file = "../output/spiegel.csv")
df %>% filter(site=="welt.de") %>% write.csv(.,file = "../output/welt.csv")
df %>% filter(site=="handelsblatt.com") %>% write.csv(.,file = "../output/handelsblatt.csv")
df %>% filter(site=="tagesschau.de") %>% write.csv(.,file = "../output/tagesschau.csv")
df %>% filter(site=="swr.de") %>% write.csv(.,file = "../output/swr.csv")
df %>% filter(site=="bild.de") %>% write.csv(.,file = "../output/bild.csv")
df %>% filter(site=="ndr.de") %>% write.csv(.,file = "../output/ndr.csv")
```

## Load by site
```{r}
focus <- read.csv("../output/focus.csv")
#spiegel <- read.csv("../output/spiegel.csv")
#bild <- read.csv("../output/bild.csv")

df_reduced <- rbind(focus, spiegel, bild)
```

```{r}
save(df_reduced, file="../output/df_reduced")
```

